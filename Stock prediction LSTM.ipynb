{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34DVNKgqQY21"
   },
   "source": [
    "# 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cWUxAQrGlq6"
   },
   "source": [
    "## 1.1. Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U7C4snIcNl22",
    "outputId": "d7c88f52-fc21-46bc-8343-f234bf00f06b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date symbol        open       close         low        high  \\\n",
      "0  2016-01-05   WLTW  123.430000  125.839996  122.309998  126.250000   \n",
      "1  2016-01-06   WLTW  125.239998  119.980003  119.940002  125.540001   \n",
      "2  2016-01-07   WLTW  116.379997  114.949997  114.930000  119.739998   \n",
      "3  2016-01-08   WLTW  115.480003  116.620003  113.500000  117.440002   \n",
      "4  2016-01-11   WLTW  117.010002  114.970001  114.089996  117.330002   \n",
      "\n",
      "      volume  \n",
      "0  2163600.0  \n",
      "1  2386400.0  \n",
      "2  2489500.0  \n",
      "3  2006300.0  \n",
      "4  1408600.0  \n"
     ]
    }
   ],
   "source": [
    "# Code to download file into Colaboratory:\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "id = '1kv1w7tpK_ax4Yid2bUIr2GP1mhHK2PM0'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('price-split-adjusted.csv')\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"price-split-adjusted.csv\")\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9gBSgBCQh24"
   },
   "source": [
    "## 1.2. Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "emyl1lWxGr12"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "stocks = [\"AAPL\", \"AMZN\", \"FB\", \"NFLX\", \"GOOGL\"]\n",
    "\n",
    "def preprocess_data(all_data):\n",
    "  pd.set_option('display.max_columns', None)\n",
    "\n",
    "  sequence_length = 7\n",
    "  stocks_data = {}\n",
    "\n",
    "  all_data_grouped_by_symbol = all_data.groupby('symbol')\n",
    "\n",
    "  for stock in stocks:\n",
    "    stocks_data[stock] = dict()\n",
    "    data         = all_data_grouped_by_symbol.get_group(stock).drop(columns=['symbol', 'date'])\n",
    "    # data['date'] = data['date'].apply(lambda x: time.mktime(datetime.datetime.strptime(x, \"%Y-%m-%d\").timetuple()))\n",
    "\n",
    "    normalizer = MinMaxScaler()\n",
    "    data['close']   = normalizer.fit_transform(data.close.values.reshape(-1,1))\n",
    "    data['high']    = normalizer.fit_transform(data.high.values.reshape(-1,1))\n",
    "    data['low']     = normalizer.fit_transform(data.low.values.reshape(-1,1))\n",
    "    data['open']    = normalizer.fit_transform(data.open.values.reshape(-1,1))\n",
    "    data['volume']  = normalizer.fit_transform(data.open.values.reshape(-1,1))\n",
    "    # data['date']    = normalizer.fit_transform(data.open.values.reshape(-1,1))\n",
    "\n",
    "    data = data.values.tolist()\n",
    "    \n",
    "    train_data = []\n",
    "    label_data = []\n",
    "\n",
    "    for i in range(0, len(data) - (sequence_length + 1)):\n",
    "      sequence = data[i:(i+sequence_length)]\n",
    "      target   = data[i+sequence_length+1]\n",
    "      train_data.append(sequence)\n",
    "      label_data.append(target[2])\n",
    "\n",
    "    train_data = np.array(train_data)\n",
    "    label_data = np.array(label_data)\n",
    "\n",
    "    # 80% data for training\n",
    "    stock_train_data   = train_data[0 : round(len(train_data) * 0.8)]\n",
    "    stock_train_labels = label_data[0 : round(len(train_data) * 0.8)]\n",
    "    # 20% remaining data for test\n",
    "    stock_test_data    = train_data[round(len(train_data) * 0.8) + 1 : -1]\n",
    "    stock_test_labels  = label_data[round(len(train_data) * 0.8) + 1 : -1]\n",
    "\n",
    "    #splitting training data in 10 folds (training and validation sets)\n",
    "    kfolds = KFold(n_splits=10)\n",
    "    kfolds.get_n_splits(stock_train_data)\n",
    "\n",
    "    stocks_data[stock]['train_data']    = stock_train_data\n",
    "    stocks_data[stock]['train_labels']  = stock_train_labels\n",
    "    stocks_data[stock]['test_data']     = stock_test_data\n",
    "    stocks_data[stock]['test_labels']   = stock_test_labels\n",
    "    stocks_data[stock]['split_indexes'] = kfolds\n",
    "\n",
    "    # print(stocks_data[stock]['train_data'].shape)\n",
    "    # print(stocks_data[stock]['train_labels'].shape)\n",
    "    # print(stocks_data[stock]['test_data'].shape)\n",
    "    # print(stocks_data[stock]['test_labels'].shape)\n",
    "    # print(stocks_data[stock]['split_indexes'])\n",
    "  return stocks_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIu_lkJwQ55g"
   },
   "source": [
    "\n",
    "\n",
    "# 2 - Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "13eCtR_SLUG6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Sentiment Analysis model\n",
    "class StockPredictor(nn.Module):\n",
    "    def __init__(self, inputs, n_hidden, n_output_nodes):\n",
    "        super(StockPredictor, self).__init__()\n",
    "        self.lstm = nn.LSTM(inputs, n_hidden, bidirectional=True, num_layers=2, batch_first=True)\n",
    "        self.linear1 = nn.Linear(n_hidden*2, 4)\n",
    "        self.linear2 = nn.Linear(4, n_output_nodes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, (hidden_state, cell_state) = self.lstm(x)\n",
    "        hidden_out = torch.cat((hidden_state[0,:,:],hidden_state[1,:,:]),1)\n",
    "        x = self.linear1(hidden_out)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "# --------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "TAzTo0APBZt1"
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "def train_models(inputs, n_hidden, n_output_nodes, learning_rate, epochs, stocks_data):\n",
    "  stock_models = {}\n",
    "\n",
    "  for stock in stocks:\n",
    "    start = timeit.default_timer()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model  = StockPredictor(inputs, n_hidden, n_output_nodes).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(0, epochs):\n",
    "      training_loss_overall   = 0\n",
    "      validation_loss_overall = 0\n",
    "\n",
    "      training_accuracy_overall   = 0\n",
    "      validation_accuracy_overall = 0  \n",
    "      \n",
    "      for train_indexes, validation_indexes in stocks_data[stock][\"split_indexes\"].split(stocks_data[stock][\"train_data\"]):\n",
    "        model.train()\n",
    "\n",
    "        train_input        = stocks_data[stock][\"train_data\"][train_indexes] \n",
    "        train_target       = stocks_data[stock][\"train_labels\"][train_indexes]\n",
    "        train_input_torch  = torch.from_numpy(np.array(train_input)).float().to(device)\n",
    "        train_target_torch = torch.from_numpy(np.array(train_target)).float().to(device)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(train_input_torch)\n",
    "        loss    = criterion(outputs.view(-1), train_target_torch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        train_outputs = model(train_input_torch)\n",
    "        train_loss    = criterion(train_outputs.view(-1), train_target_torch)\n",
    "\n",
    "        validation_input        = stocks_data[stock][\"train_data\"][validation_indexes]\n",
    "        validation_target       = stocks_data[stock][\"train_labels\"][validation_indexes]\n",
    "        validation_input_torch  = torch.from_numpy(np.array(validation_input)).float().to(device)\n",
    "        validation_target_torch = torch.from_numpy(np.array(validation_target)).float().to(device)\n",
    "        \n",
    "        validation_outputs = model(validation_input_torch)\n",
    "        validation_loss    = criterion(validation_outputs.view(-1), validation_target_torch)\n",
    "\n",
    "        train_loss       = train_loss.item()\n",
    "        train_acc        = np.sum(np.isclose(train_outputs.view(-1).detach().cpu().numpy(), train_target_torch.cpu().numpy(), atol=0.02) == [True]*len(train_target_torch.cpu().numpy()))/len(train_target_torch.cpu().numpy())\n",
    "        validation_loss  = validation_loss.item() \n",
    "        validation_acc   = np.sum(np.isclose(validation_outputs.view(-1).detach().cpu().numpy(), validation_target_torch.cpu().numpy(), atol=0.02) == [True]*len(validation_target_torch.cpu().numpy()))/len(validation_target_torch.cpu().numpy())\n",
    "\n",
    "        training_loss_overall       += train_loss\n",
    "        validation_loss_overall     += validation_loss\n",
    "        training_accuracy_overall   += train_acc\n",
    "        validation_accuracy_overall += validation_acc\n",
    "\n",
    "      if (((epoch % round(epochs * 0.2)) == (round(epochs*0.2)-1)) or epoch == 0):\n",
    "        print('Stock: %s, Epoch: %d, TrainLoss: %.6f, TrainAcc: %.6f, Val.Loss: %.6f, ValAcc: %.6f' %(stock, epoch + 1, training_loss_overall/10, training_accuracy_overall/10, validation_loss_overall/10, validation_accuracy_overall/10))\n",
    "      stop = timeit.default_timer()\n",
    "    stock_models[stock] = model      \n",
    "    print('------------------------ Time: %f  --------------' %(stop-start))\n",
    "  return stock_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "iC51v_HIfbFc"
   },
   "outputs": [],
   "source": [
    "def evaluate_models(stock_models, stocks_data):\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  criterion = nn.MSELoss()\n",
    "\n",
    "  for stock in stock_models:\n",
    "    start = timeit.default_timer()\n",
    "    test_input  = stocks_data[stock][\"test_data\"]\n",
    "    test_target = stocks_data[stock][\"test_labels\"]\n",
    "    test_input_torch  = torch.from_numpy(np.array(test_input)).float().to(device)\n",
    "    test_target_torch = torch.from_numpy(np.array(test_target)).float().to(device)\n",
    "    \n",
    "    model = stock_models[stock]\n",
    "    model.eval()    \n",
    "    test_outputs  = model(test_input_torch)\n",
    "    test_loss     = criterion(test_outputs.view(-1), test_target_torch)\n",
    "\n",
    "    test_loss  = test_loss.item()\n",
    "    test_acc   = np.sum(np.isclose(test_outputs.view(-1).detach().cpu().numpy(), test_target_torch.cpu().numpy(), atol=0.02) == [True]*len(test_target_torch.cpu().numpy()))/len(test_target_torch.cpu().numpy())\n",
    "\n",
    "    end = timeit.default_timer()\n",
    "\n",
    "    print('Stock: %s, TestLoss: %.6f, TestAcc: %.6f, Time: %6f' %(stock, test_loss, test_acc, (end-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70XfpjgyfT8i"
   },
   "source": [
    "## Best Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EtJZUl13C_xO",
    "outputId": "a6f8c264-3c78-4fdc-f9af-05e8328afeb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock: AAPL, Epoch: 1, TrainLoss: 0.150896, TrainAcc: 0.044735, Val.Loss: 0.050860, ValAcc: 0.007857\n",
      "Stock: AAPL, Epoch: 40, TrainLoss: 0.000575, TrainAcc: 0.638072, Val.Loss: 0.000580, ValAcc: 0.638921\n",
      "Stock: AAPL, Epoch: 80, TrainLoss: 0.000338, TrainAcc: 0.777853, Val.Loss: 0.000342, ValAcc: 0.775902\n",
      "Stock: AAPL, Epoch: 120, TrainLoss: 0.000298, TrainAcc: 0.813492, Val.Loss: 0.000306, ValAcc: 0.815137\n",
      "Stock: AAPL, Epoch: 160, TrainLoss: 0.000288, TrainAcc: 0.821966, Val.Loss: 0.000297, ValAcc: 0.822249\n",
      "Stock: AAPL, Epoch: 200, TrainLoss: 0.000284, TrainAcc: 0.826004, Val.Loss: 0.000292, ValAcc: 0.829367\n",
      "------------------------ Time: 25.295379  --------------\n",
      "Stock: AMZN, Epoch: 1, TrainLoss: 0.009507, TrainAcc: 0.154187, Val.Loss: 0.012937, ValAcc: 0.090000\n",
      "Stock: AMZN, Epoch: 40, TrainLoss: 0.000114, TrainAcc: 0.952957, Val.Loss: 0.000123, ValAcc: 0.949296\n",
      "Stock: AMZN, Epoch: 80, TrainLoss: 0.000107, TrainAcc: 0.958976, Val.Loss: 0.000115, ValAcc: 0.954296\n",
      "Stock: AMZN, Epoch: 120, TrainLoss: 0.000103, TrainAcc: 0.962539, Val.Loss: 0.000109, ValAcc: 0.957153\n",
      "Stock: AMZN, Epoch: 160, TrainLoss: 0.000100, TrainAcc: 0.964915, Val.Loss: 0.000107, ValAcc: 0.961439\n",
      "Stock: AMZN, Epoch: 200, TrainLoss: 0.000098, TrainAcc: 0.965311, Val.Loss: 0.000105, ValAcc: 0.962867\n",
      "------------------------ Time: 25.144679  --------------\n",
      "Stock: FB, Epoch: 1, TrainLoss: 0.081279, TrainAcc: 0.029167, Val.Loss: 0.012432, ValAcc: 0.130000\n",
      "Stock: FB, Epoch: 40, TrainLoss: 0.000500, TrainAcc: 0.739722, Val.Loss: 0.000501, ValAcc: 0.738750\n",
      "Stock: FB, Epoch: 80, TrainLoss: 0.000431, TrainAcc: 0.773889, Val.Loss: 0.000431, ValAcc: 0.772500\n",
      "Stock: FB, Epoch: 120, TrainLoss: 0.000395, TrainAcc: 0.789167, Val.Loss: 0.000398, ValAcc: 0.790000\n",
      "Stock: FB, Epoch: 160, TrainLoss: 0.000373, TrainAcc: 0.808056, Val.Loss: 0.000374, ValAcc: 0.803750\n",
      "Stock: FB, Epoch: 200, TrainLoss: 0.000359, TrainAcc: 0.815000, Val.Loss: 0.000362, ValAcc: 0.808750\n",
      "------------------------ Time: 24.441511  --------------\n",
      "Stock: NFLX, Epoch: 1, TrainLoss: 0.058108, TrainAcc: 0.066127, Val.Loss: 0.083647, ValAcc: 0.024286\n",
      "Stock: NFLX, Epoch: 40, TrainLoss: 0.000233, TrainAcc: 0.887383, Val.Loss: 0.000234, ValAcc: 0.885831\n",
      "Stock: NFLX, Epoch: 80, TrainLoss: 0.000221, TrainAcc: 0.895778, Val.Loss: 0.000232, ValAcc: 0.890132\n",
      "Stock: NFLX, Epoch: 120, TrainLoss: 0.000205, TrainAcc: 0.905202, Val.Loss: 0.000207, ValAcc: 0.903683\n",
      "Stock: NFLX, Epoch: 160, TrainLoss: 0.000199, TrainAcc: 0.910746, Val.Loss: 0.000207, ValAcc: 0.904392\n",
      "Stock: NFLX, Epoch: 200, TrainLoss: 0.000194, TrainAcc: 0.914468, Val.Loss: 0.000203, ValAcc: 0.909402\n",
      "------------------------ Time: 25.240722  --------------\n",
      "Stock: GOOGL, Epoch: 1, TrainLoss: 0.030335, TrainAcc: 0.051714, Val.Loss: 0.024794, ValAcc: 0.057857\n",
      "Stock: GOOGL, Epoch: 40, TrainLoss: 0.000219, TrainAcc: 0.890630, Val.Loss: 0.000223, ValAcc: 0.888045\n",
      "Stock: GOOGL, Epoch: 80, TrainLoss: 0.000201, TrainAcc: 0.905755, Val.Loss: 0.000206, ValAcc: 0.910137\n",
      "Stock: GOOGL, Epoch: 120, TrainLoss: 0.000194, TrainAcc: 0.912487, Val.Loss: 0.000199, ValAcc: 0.912989\n",
      "Stock: GOOGL, Epoch: 160, TrainLoss: 0.000191, TrainAcc: 0.914468, Val.Loss: 0.000196, ValAcc: 0.913703\n",
      "Stock: GOOGL, Epoch: 200, TrainLoss: 0.000190, TrainAcc: 0.915022, Val.Loss: 0.000195, ValAcc: 0.912989\n",
      "------------------------ Time: 25.360819  --------------\n",
      "Stock: AAPL, TestLoss: 0.000611, TestAcc: 0.713467, Time: 0.002841\n",
      "Stock: AMZN, TestLoss: 0.006683, TestAcc: 0.252149, Time: 0.002440\n",
      "Stock: FB, TestLoss: 0.000627, TestAcc: 0.535354, Time: 0.002194\n",
      "Stock: NFLX, TestLoss: 0.001443, TestAcc: 0.507163, Time: 0.002283\n",
      "Stock: GOOGL, TestLoss: 0.001172, TestAcc: 0.315186, Time: 0.002227\n",
      "Overall Running Time:  125.49649816599958\n"
     ]
    }
   ],
   "source": [
    "processed_data = preprocess_data(all_data)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "my_models      = train_models(inputs=5, n_hidden=10, n_output_nodes=1, learning_rate=0.01, epochs=200, stocks_data=processed_data)\n",
    "evaluate_models(my_models, processed_data)\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Overall Running Time: ', stop - start)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gDf7raJQB7J"
   },
   "source": [
    "Hyper Parameter Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ONcuJUb-QAsF",
    "outputId": "e5754ead-c29b-4a03-8d0a-207e430b3bdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock: AAPL, Epoch: 1, TrainLoss: 0.057437, TrainAcc: 0.063437, Val.Loss: 0.068635, ValAcc: 0.066429\n",
      "Stock: AAPL, Epoch: 20, TrainLoss: 0.000415, TrainAcc: 0.731127, Val.Loss: 0.000419, ValAcc: 0.737381\n",
      "Stock: AAPL, Epoch: 40, TrainLoss: 0.000340, TrainAcc: 0.779041, Val.Loss: 0.000342, ValAcc: 0.771586\n",
      "Stock: AAPL, Epoch: 60, TrainLoss: 0.000310, TrainAcc: 0.800898, Val.Loss: 0.000314, ValAcc: 0.800831\n",
      "Stock: AAPL, Epoch: 80, TrainLoss: 0.000295, TrainAcc: 0.819035, Val.Loss: 0.000299, ValAcc: 0.819402\n",
      "Stock: AAPL, Epoch: 100, TrainLoss: 0.000295, TrainAcc: 0.817135, Val.Loss: 0.000302, ValAcc: 0.817259\n",
      "------------------------\n",
      "Stock: AMZN, Epoch: 1, TrainLoss: 0.033808, TrainAcc: 0.063908, Val.Loss: 0.003271, ValAcc: 0.207634\n",
      "Stock: AMZN, Epoch: 20, TrainLoss: 0.000183, TrainAcc: 0.903459, Val.Loss: 0.000187, ValAcc: 0.894407\n",
      "Stock: AMZN, Epoch: 40, TrainLoss: 0.000150, TrainAcc: 0.923734, Val.Loss: 0.000151, ValAcc: 0.921494\n",
      "Stock: AMZN, Epoch: 60, TrainLoss: 0.000127, TrainAcc: 0.943137, Val.Loss: 0.000129, ValAcc: 0.942898\n",
      "Stock: AMZN, Epoch: 80, TrainLoss: 0.000112, TrainAcc: 0.954145, Val.Loss: 0.000114, ValAcc: 0.953592\n",
      "Stock: AMZN, Epoch: 100, TrainLoss: 0.000107, TrainAcc: 0.955016, Val.Loss: 0.000113, ValAcc: 0.954301\n",
      "------------------------\n",
      "Stock: FB, Epoch: 1, TrainLoss: 0.052603, TrainAcc: 0.056944, Val.Loss: 0.011536, ValAcc: 0.228750\n",
      "Stock: FB, Epoch: 20, TrainLoss: 0.000745, TrainAcc: 0.654028, Val.Loss: 0.000746, ValAcc: 0.655000\n",
      "Stock: FB, Epoch: 40, TrainLoss: 0.000643, TrainAcc: 0.683611, Val.Loss: 0.000647, ValAcc: 0.686250\n",
      "Stock: FB, Epoch: 60, TrainLoss: 0.000518, TrainAcc: 0.734583, Val.Loss: 0.000522, ValAcc: 0.727500\n",
      "Stock: FB, Epoch: 80, TrainLoss: 0.000386, TrainAcc: 0.794583, Val.Loss: 0.000388, ValAcc: 0.795000\n",
      "Stock: FB, Epoch: 100, TrainLoss: 0.000361, TrainAcc: 0.809583, Val.Loss: 0.000368, ValAcc: 0.801250\n",
      "------------------------\n",
      "Stock: NFLX, Epoch: 1, TrainLoss: 0.348728, TrainAcc: 0.000000, Val.Loss: 0.271140, ValAcc: 0.000000\n",
      "Stock: NFLX, Epoch: 20, TrainLoss: 0.000601, TrainAcc: 0.727170, Val.Loss: 0.000597, ValAcc: 0.726165\n",
      "Stock: NFLX, Epoch: 40, TrainLoss: 0.000498, TrainAcc: 0.746969, Val.Loss: 0.000498, ValAcc: 0.746809\n",
      "Stock: NFLX, Epoch: 60, TrainLoss: 0.000414, TrainAcc: 0.784982, Val.Loss: 0.000413, ValAcc: 0.786733\n",
      "Stock: NFLX, Epoch: 80, TrainLoss: 0.000330, TrainAcc: 0.842320, Val.Loss: 0.000330, ValAcc: 0.839498\n",
      "Stock: NFLX, Epoch: 100, TrainLoss: 0.000266, TrainAcc: 0.875266, Val.Loss: 0.000266, ValAcc: 0.874417\n",
      "------------------------\n",
      "Stock: GOOGL, Epoch: 1, TrainLoss: 0.030801, TrainAcc: 0.038964, Val.Loss: 0.033221, ValAcc: 0.005000\n",
      "Stock: GOOGL, Epoch: 20, TrainLoss: 0.000342, TrainAcc: 0.804862, Val.Loss: 0.000343, ValAcc: 0.803222\n",
      "Stock: GOOGL, Epoch: 40, TrainLoss: 0.000284, TrainAcc: 0.842559, Val.Loss: 0.000285, ValAcc: 0.842462\n",
      "Stock: GOOGL, Epoch: 60, TrainLoss: 0.000242, TrainAcc: 0.871386, Val.Loss: 0.000243, ValAcc: 0.873799\n",
      "Stock: GOOGL, Epoch: 80, TrainLoss: 0.000215, TrainAcc: 0.891264, Val.Loss: 0.000216, ValAcc: 0.893019\n",
      "Stock: GOOGL, Epoch: 100, TrainLoss: 0.000207, TrainAcc: 0.899184, Val.Loss: 0.000211, ValAcc: 0.900861\n",
      "------------------------\n",
      "Stock: AAPL, TestLoss: 0.000632, TestAcc: 0.704871\n",
      "Stock: AMZN, TestLoss: 0.001084, TestAcc: 0.424069\n",
      "Stock: FB, TestLoss: 0.002548, TestAcc: 0.161616\n",
      "Stock: NFLX, TestLoss: 0.002520, TestAcc: 0.452722\n",
      "Stock: GOOGL, TestLoss: 0.001280, TestAcc: 0.292264\n"
     ]
    }
   ],
   "source": [
    "processed_data = preprocess_data(all_data)\n",
    "n_hidden       = 5\n",
    "n_output_nodes = 1\n",
    "learning_rate  = 0.01\n",
    "epochs         = 100\n",
    "\n",
    "my_models      = train_models(5, n_hidden, n_output_nodes, learning_rate, epochs, processed_data)\n",
    "evaluate_models(my_models, processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKqcp08JQxXt",
    "outputId": "c18fd96a-dce5-474f-850c-67ecbac5f378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock: AAPL, Epoch: 1, TrainLoss: 0.272317, TrainAcc: 0.011956, Val.Loss: 0.138030, ValAcc: 0.025000\n",
      "Stock: AAPL, Epoch: 40, TrainLoss: 0.000560, TrainAcc: 0.650345, Val.Loss: 0.000564, ValAcc: 0.653156\n",
      "Stock: AAPL, Epoch: 80, TrainLoss: 0.000417, TrainAcc: 0.725029, Val.Loss: 0.000419, ValAcc: 0.725198\n",
      "Stock: AAPL, Epoch: 120, TrainLoss: 0.000328, TrainAcc: 0.788309, Val.Loss: 0.000335, ValAcc: 0.777270\n",
      "Stock: AAPL, Epoch: 160, TrainLoss: 0.000299, TrainAcc: 0.811669, Val.Loss: 0.000302, ValAcc: 0.810826\n",
      "Stock: AAPL, Epoch: 200, TrainLoss: 0.000295, TrainAcc: 0.817134, Val.Loss: 0.000303, ValAcc: 0.815111\n",
      "------------------------\n",
      "Stock: AMZN, Epoch: 1, TrainLoss: 0.065837, TrainAcc: 0.060570, Val.Loss: 0.026562, ValAcc: 0.061429\n",
      "Stock: AMZN, Epoch: 40, TrainLoss: 0.000187, TrainAcc: 0.900212, Val.Loss: 0.000189, ValAcc: 0.897234\n",
      "Stock: AMZN, Epoch: 80, TrainLoss: 0.000119, TrainAcc: 0.950502, Val.Loss: 0.000122, ValAcc: 0.947888\n",
      "Stock: AMZN, Epoch: 120, TrainLoss: 0.000111, TrainAcc: 0.953669, Val.Loss: 0.000116, ValAcc: 0.952867\n",
      "Stock: AMZN, Epoch: 160, TrainLoss: 0.000108, TrainAcc: 0.955887, Val.Loss: 0.000113, ValAcc: 0.955724\n",
      "Stock: AMZN, Epoch: 200, TrainLoss: 0.000106, TrainAcc: 0.958422, Val.Loss: 0.000112, ValAcc: 0.956439\n",
      "------------------------\n",
      "Stock: FB, Epoch: 1, TrainLoss: 0.036311, TrainAcc: 0.071111, Val.Loss: 0.020238, ValAcc: 0.025000\n",
      "Stock: FB, Epoch: 40, TrainLoss: 0.000469, TrainAcc: 0.755139, Val.Loss: 0.000469, ValAcc: 0.752500\n",
      "Stock: FB, Epoch: 80, TrainLoss: 0.000394, TrainAcc: 0.791111, Val.Loss: 0.000396, ValAcc: 0.783750\n",
      "Stock: FB, Epoch: 120, TrainLoss: 0.000375, TrainAcc: 0.802083, Val.Loss: 0.000377, ValAcc: 0.808750\n",
      "Stock: FB, Epoch: 160, TrainLoss: 0.000360, TrainAcc: 0.813750, Val.Loss: 0.000363, ValAcc: 0.816250\n",
      "Stock: FB, Epoch: 200, TrainLoss: 0.000351, TrainAcc: 0.817917, Val.Loss: 0.000357, ValAcc: 0.820000\n",
      "------------------------\n",
      "Stock: NFLX, Epoch: 1, TrainLoss: 0.009987, TrainAcc: 0.167161, Val.Loss: 0.008485, ValAcc: 0.215952\n",
      "Stock: NFLX, Epoch: 40, TrainLoss: 0.000212, TrainAcc: 0.902429, Val.Loss: 0.000216, ValAcc: 0.897969\n",
      "Stock: NFLX, Epoch: 80, TrainLoss: 0.000198, TrainAcc: 0.912963, Val.Loss: 0.000203, ValAcc: 0.907249\n",
      "Stock: NFLX, Epoch: 120, TrainLoss: 0.000192, TrainAcc: 0.917081, Val.Loss: 0.000196, ValAcc: 0.915101\n",
      "Stock: NFLX, Epoch: 160, TrainLoss: 0.000190, TrainAcc: 0.917398, Val.Loss: 0.000195, ValAcc: 0.914402\n",
      "Stock: NFLX, Epoch: 200, TrainLoss: 0.000188, TrainAcc: 0.918903, Val.Loss: 0.000193, ValAcc: 0.914402\n",
      "------------------------\n",
      "Stock: GOOGL, Epoch: 1, TrainLoss: 0.052839, TrainAcc: 0.062565, Val.Loss: 0.005255, ValAcc: 0.234554\n",
      "Stock: GOOGL, Epoch: 40, TrainLoss: 0.000325, TrainAcc: 0.820385, Val.Loss: 0.000325, ValAcc: 0.821084\n",
      "Stock: GOOGL, Epoch: 80, TrainLoss: 0.000223, TrainAcc: 0.883898, Val.Loss: 0.000224, ValAcc: 0.880887\n",
      "Stock: GOOGL, Epoch: 120, TrainLoss: 0.000201, TrainAcc: 0.903935, Val.Loss: 0.000205, ValAcc: 0.907285\n",
      "Stock: GOOGL, Epoch: 160, TrainLoss: 0.000197, TrainAcc: 0.909637, Val.Loss: 0.000201, ValAcc: 0.910836\n",
      "Stock: GOOGL, Epoch: 200, TrainLoss: 0.000195, TrainAcc: 0.910904, Val.Loss: 0.000199, ValAcc: 0.914412\n",
      "------------------------\n",
      "Stock: AAPL, TestLoss: 0.000643, TestAcc: 0.699140\n",
      "Stock: AMZN, TestLoss: 0.002512, TestAcc: 0.306590\n",
      "Stock: FB, TestLoss: 0.000728, TestAcc: 0.439394\n",
      "Stock: NFLX, TestLoss: 0.001392, TestAcc: 0.550143\n",
      "Stock: GOOGL, TestLoss: 0.001422, TestAcc: 0.283668\n"
     ]
    }
   ],
   "source": [
    "processed_data = preprocess_data(all_data)\n",
    "n_hidden       = 10\n",
    "n_output_nodes = 1\n",
    "learning_rate  = 0.01\n",
    "epochs         = 200\n",
    "\n",
    "my_models      = train_models(5, n_hidden, n_output_nodes, learning_rate, epochs, processed_data)\n",
    "evaluate_models(my_models, processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4IL5qUKKSvN-",
    "outputId": "2094580c-ad57-46aa-c7bf-3f23eeeb9653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock: AAPL, Epoch: 1, TrainLoss: 0.016795, TrainAcc: 0.143885, Val.Loss: 0.029048, ValAcc: 0.141429\n",
      "Stock: AAPL, Epoch: 60, TrainLoss: 0.000292, TrainAcc: 0.818244, Val.Loss: 0.000303, ValAcc: 0.822254\n",
      "Stock: AAPL, Epoch: 120, TrainLoss: 0.000277, TrainAcc: 0.832182, Val.Loss: 0.000284, ValAcc: 0.825805\n",
      "Stock: AAPL, Epoch: 180, TrainLoss: 0.000272, TrainAcc: 0.834954, Val.Loss: 0.000279, ValAcc: 0.832229\n",
      "Stock: AAPL, Epoch: 240, TrainLoss: 0.000269, TrainAcc: 0.836221, Val.Loss: 0.000276, ValAcc: 0.835800\n",
      "Stock: AAPL, Epoch: 300, TrainLoss: 0.000268, TrainAcc: 0.836537, Val.Loss: 0.000273, ValAcc: 0.840086\n",
      "------------------------\n",
      "Stock: AMZN, Epoch: 1, TrainLoss: 0.010805, TrainAcc: 0.153797, Val.Loss: 0.013498, ValAcc: 0.062857\n",
      "Stock: AMZN, Epoch: 60, TrainLoss: 0.000117, TrainAcc: 0.951374, Val.Loss: 0.000119, ValAcc: 0.947882\n",
      "Stock: AMZN, Epoch: 120, TrainLoss: 0.000105, TrainAcc: 0.958342, Val.Loss: 0.000107, ValAcc: 0.957867\n",
      "Stock: AMZN, Epoch: 180, TrainLoss: 0.000101, TrainAcc: 0.962936, Val.Loss: 0.000108, ValAcc: 0.960010\n",
      "Stock: AMZN, Epoch: 240, TrainLoss: 0.000100, TrainAcc: 0.963886, Val.Loss: 0.000107, ValAcc: 0.961434\n",
      "Stock: AMZN, Epoch: 300, TrainLoss: 0.000098, TrainAcc: 0.964519, Val.Loss: 0.000106, ValAcc: 0.962158\n",
      "------------------------\n",
      "Stock: FB, Epoch: 1, TrainLoss: 0.112798, TrainAcc: 0.040417, Val.Loss: 0.025157, ValAcc: 0.053750\n",
      "Stock: FB, Epoch: 60, TrainLoss: 0.000460, TrainAcc: 0.764028, Val.Loss: 0.000461, ValAcc: 0.757500\n",
      "Stock: FB, Epoch: 120, TrainLoss: 0.000403, TrainAcc: 0.781528, Val.Loss: 0.000404, ValAcc: 0.773750\n",
      "Stock: FB, Epoch: 180, TrainLoss: 0.000374, TrainAcc: 0.806528, Val.Loss: 0.000377, ValAcc: 0.811250\n",
      "Stock: FB, Epoch: 240, TrainLoss: 0.000356, TrainAcc: 0.813611, Val.Loss: 0.000365, ValAcc: 0.820000\n",
      "Stock: FB, Epoch: 300, TrainLoss: 0.000350, TrainAcc: 0.816806, Val.Loss: 0.000361, ValAcc: 0.812500\n",
      "------------------------\n",
      "Stock: NFLX, Epoch: 1, TrainLoss: 0.013315, TrainAcc: 0.146258, Val.Loss: 0.011416, ValAcc: 0.176682\n",
      "Stock: NFLX, Epoch: 60, TrainLoss: 0.000202, TrainAcc: 0.909874, Val.Loss: 0.000205, ValAcc: 0.907964\n",
      "Stock: NFLX, Epoch: 120, TrainLoss: 0.000195, TrainAcc: 0.913121, Val.Loss: 0.000199, ValAcc: 0.908703\n",
      "Stock: NFLX, Epoch: 180, TrainLoss: 0.000189, TrainAcc: 0.916527, Val.Loss: 0.000193, ValAcc: 0.910831\n",
      "Stock: NFLX, Epoch: 240, TrainLoss: 0.000187, TrainAcc: 0.918031, Val.Loss: 0.000191, ValAcc: 0.914402\n",
      "Stock: NFLX, Epoch: 300, TrainLoss: 0.000186, TrainAcc: 0.918190, Val.Loss: 0.000193, ValAcc: 0.912969\n",
      "------------------------\n",
      "Stock: GOOGL, Epoch: 1, TrainLoss: 0.105326, TrainAcc: 0.037688, Val.Loss: 0.028987, ValAcc: 0.035000\n",
      "Stock: GOOGL, Epoch: 60, TrainLoss: 0.000268, TrainAcc: 0.856418, Val.Loss: 0.000268, ValAcc: 0.858840\n",
      "Stock: GOOGL, Epoch: 120, TrainLoss: 0.000214, TrainAcc: 0.893956, Val.Loss: 0.000215, ValAcc: 0.892295\n",
      "Stock: GOOGL, Epoch: 180, TrainLoss: 0.000204, TrainAcc: 0.901322, Val.Loss: 0.000209, ValAcc: 0.904433\n",
      "Stock: GOOGL, Epoch: 240, TrainLoss: 0.000198, TrainAcc: 0.909162, Val.Loss: 0.000199, ValAcc: 0.912984\n",
      "Stock: GOOGL, Epoch: 300, TrainLoss: 0.000193, TrainAcc: 0.912884, Val.Loss: 0.000199, ValAcc: 0.911565\n",
      "------------------------\n",
      "Stock: AAPL, TestLoss: 0.000604, TestAcc: 0.716332\n",
      "Stock: AMZN, TestLoss: 0.010191, TestAcc: 0.237822\n",
      "Stock: FB, TestLoss: 0.001252, TestAcc: 0.252525\n",
      "Stock: NFLX, TestLoss: 0.001412, TestAcc: 0.527221\n",
      "Stock: GOOGL, TestLoss: 0.001194, TestAcc: 0.315186\n"
     ]
    }
   ],
   "source": [
    "processed_data = preprocess_data(all_data)\n",
    "n_hidden       = 10\n",
    "n_output_nodes = 1\n",
    "learning_rate  = 0.01\n",
    "epochs         = 300\n",
    "\n",
    "my_models      = train_models(5, n_hidden, n_output_nodes, learning_rate, epochs, processed_data)\n",
    "evaluate_models(my_models, processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5Q3EV00S3TJ",
    "outputId": "e540704c-7f4a-4c1e-834b-1d2e0e11c8c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock: AAPL, Epoch: 1, TrainLoss: 0.056454, TrainAcc: 0.061139, Val.Loss: 0.025785, ValAcc: 0.029124\n",
      "Stock: AAPL, Epoch: 80, TrainLoss: 0.000316, TrainAcc: 0.801929, Val.Loss: 0.000324, ValAcc: 0.802285\n",
      "Stock: AAPL, Epoch: 160, TrainLoss: 0.000288, TrainAcc: 0.820461, Val.Loss: 0.000296, ValAcc: 0.822234\n",
      "Stock: AAPL, Epoch: 240, TrainLoss: 0.000281, TrainAcc: 0.825767, Val.Loss: 0.000289, ValAcc: 0.830076\n",
      "Stock: AAPL, Epoch: 320, TrainLoss: 0.000278, TrainAcc: 0.828221, Val.Loss: 0.000286, ValAcc: 0.831494\n",
      "Stock: AAPL, Epoch: 400, TrainLoss: 0.000275, TrainAcc: 0.831390, Val.Loss: 0.000282, ValAcc: 0.835785\n",
      "------------------------\n",
      "Stock: AMZN, Epoch: 1, TrainLoss: 0.011771, TrainAcc: 0.133600, Val.Loss: 0.015055, ValAcc: 0.034286\n",
      "Stock: AMZN, Epoch: 80, TrainLoss: 0.000107, TrainAcc: 0.957788, Val.Loss: 0.000113, ValAcc: 0.954296\n",
      "Stock: AMZN, Epoch: 160, TrainLoss: 0.000100, TrainAcc: 0.964519, Val.Loss: 0.000106, ValAcc: 0.961439\n",
      "Stock: AMZN, Epoch: 240, TrainLoss: 0.000097, TrainAcc: 0.965628, Val.Loss: 0.000103, ValAcc: 0.962867\n",
      "Stock: AMZN, Epoch: 320, TrainLoss: 0.000095, TrainAcc: 0.966737, Val.Loss: 0.000102, ValAcc: 0.964296\n",
      "Stock: AMZN, Epoch: 400, TrainLoss: 0.000091, TrainAcc: 0.967608, Val.Loss: 0.000094, ValAcc: 0.965724\n",
      "------------------------\n",
      "Stock: FB, Epoch: 1, TrainLoss: 0.116792, TrainAcc: 0.024306, Val.Loss: 0.037877, ValAcc: 0.022500\n",
      "Stock: FB, Epoch: 80, TrainLoss: 0.000369, TrainAcc: 0.807778, Val.Loss: 0.000371, ValAcc: 0.802500\n",
      "Stock: FB, Epoch: 160, TrainLoss: 0.000337, TrainAcc: 0.822500, Val.Loss: 0.000339, ValAcc: 0.822500\n",
      "Stock: FB, Epoch: 240, TrainLoss: 0.000334, TrainAcc: 0.816250, Val.Loss: 0.000343, ValAcc: 0.818750\n",
      "Stock: FB, Epoch: 320, TrainLoss: 0.000325, TrainAcc: 0.823750, Val.Loss: 0.000333, ValAcc: 0.825000\n",
      "Stock: FB, Epoch: 400, TrainLoss: 0.000331, TrainAcc: 0.815278, Val.Loss: 0.000339, ValAcc: 0.815000\n",
      "------------------------\n",
      "Stock: NFLX, Epoch: 1, TrainLoss: 0.040321, TrainAcc: 0.087975, Val.Loss: 0.047671, ValAcc: 0.027143\n",
      "Stock: NFLX, Epoch: 80, TrainLoss: 0.000204, TrainAcc: 0.907578, Val.Loss: 0.000213, ValAcc: 0.900826\n",
      "Stock: NFLX, Epoch: 160, TrainLoss: 0.000189, TrainAcc: 0.917319, Val.Loss: 0.000198, ValAcc: 0.911545\n",
      "Stock: NFLX, Epoch: 240, TrainLoss: 0.000186, TrainAcc: 0.918824, Val.Loss: 0.000195, ValAcc: 0.913683\n",
      "Stock: NFLX, Epoch: 320, TrainLoss: 0.000184, TrainAcc: 0.918903, Val.Loss: 0.000194, ValAcc: 0.911540\n",
      "Stock: NFLX, Epoch: 400, TrainLoss: 0.000183, TrainAcc: 0.919537, Val.Loss: 0.000193, ValAcc: 0.909397\n",
      "------------------------\n",
      "Stock: GOOGL, Epoch: 1, TrainLoss: 0.083321, TrainAcc: 0.038242, Val.Loss: 0.038979, ValAcc: 0.104286\n",
      "Stock: GOOGL, Epoch: 80, TrainLoss: 0.000237, TrainAcc: 0.875266, Val.Loss: 0.000240, ValAcc: 0.875937\n",
      "Stock: GOOGL, Epoch: 160, TrainLoss: 0.000202, TrainAcc: 0.905282, Val.Loss: 0.000206, ValAcc: 0.907999\n",
      "Stock: GOOGL, Epoch: 240, TrainLoss: 0.000194, TrainAcc: 0.911062, Val.Loss: 0.000199, ValAcc: 0.910127\n",
      "Stock: GOOGL, Epoch: 320, TrainLoss: 0.000193, TrainAcc: 0.912884, Val.Loss: 0.000198, ValAcc: 0.912989\n",
      "Stock: GOOGL, Epoch: 400, TrainLoss: 0.000193, TrainAcc: 0.912329, Val.Loss: 0.000198, ValAcc: 0.912275\n",
      "------------------------\n",
      "Stock: AAPL, TestLoss: 0.000616, TestAcc: 0.699140\n",
      "Stock: AMZN, TestLoss: 0.048454, TestAcc: 0.091691\n",
      "Stock: FB, TestLoss: 0.021707, TestAcc: 0.095960\n",
      "Stock: NFLX, TestLoss: 0.001413, TestAcc: 0.510029\n",
      "Stock: GOOGL, TestLoss: 0.001382, TestAcc: 0.289398\n"
     ]
    }
   ],
   "source": [
    "processed_data = preprocess_data(all_data)\n",
    "n_hidden       = 15\n",
    "n_output_nodes = 1\n",
    "learning_rate  = 0.01\n",
    "epochs         = 400\n",
    "\n",
    "my_models      = train_models(5, n_hidden, n_output_nodes, learning_rate, epochs, processed_data)\n",
    "evaluate_models(my_models, processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sFU0QcZeTI6H",
    "outputId": "6800a176-d166-4b85-8fb2-9ef240026b8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock: AAPL, Epoch: 1, TrainLoss: 0.013490, TrainAcc: 0.195665, Val.Loss: 0.026480, ValAcc: 0.169286\n",
      "Stock: AAPL, Epoch: 200, TrainLoss: 0.000275, TrainAcc: 0.828142, Val.Loss: 0.000282, ValAcc: 0.831515\n",
      "Stock: AAPL, Epoch: 400, TrainLoss: 0.000268, TrainAcc: 0.835904, Val.Loss: 0.000276, ValAcc: 0.835805\n",
      "Stock: AAPL, Epoch: 600, TrainLoss: 0.000266, TrainAcc: 0.837092, Val.Loss: 0.000276, ValAcc: 0.836525\n",
      "Stock: AAPL, Epoch: 800, TrainLoss: 0.000252, TrainAcc: 0.845329, Val.Loss: 0.000264, ValAcc: 0.842229\n",
      "Stock: AAPL, Epoch: 1000, TrainLoss: 0.000237, TrainAcc: 0.854673, Val.Loss: 0.000243, ValAcc: 0.853647\n",
      "------------------------\n",
      "Stock: AMZN, Epoch: 1, TrainLoss: 0.025336, TrainAcc: 0.097008, Val.Loss: 0.013060, ValAcc: 0.125947\n",
      "Stock: AMZN, Epoch: 200, TrainLoss: 0.000098, TrainAcc: 0.964599, Val.Loss: 0.000105, ValAcc: 0.963582\n",
      "Stock: AMZN, Epoch: 400, TrainLoss: 0.000097, TrainAcc: 0.965628, Val.Loss: 0.000105, ValAcc: 0.962872\n",
      "Stock: AMZN, Epoch: 600, TrainLoss: 0.000091, TrainAcc: 0.967054, Val.Loss: 0.000097, ValAcc: 0.962867\n",
      "Stock: AMZN, Epoch: 800, TrainLoss: 0.000089, TrainAcc: 0.969034, Val.Loss: 0.000093, ValAcc: 0.965724\n",
      "Stock: AMZN, Epoch: 1000, TrainLoss: 0.000086, TrainAcc: 0.971409, Val.Loss: 0.000092, ValAcc: 0.965724\n",
      "------------------------\n",
      "Stock: FB, Epoch: 1, TrainLoss: 0.283340, TrainAcc: 0.000139, Val.Loss: 0.157387, ValAcc: 0.000000\n",
      "Stock: FB, Epoch: 200, TrainLoss: 0.000359, TrainAcc: 0.815694, Val.Loss: 0.000364, ValAcc: 0.811250\n",
      "Stock: FB, Epoch: 400, TrainLoss: 0.000347, TrainAcc: 0.815833, Val.Loss: 0.000357, ValAcc: 0.811250\n",
      "Stock: FB, Epoch: 600, TrainLoss: 0.000347, TrainAcc: 0.811944, Val.Loss: 0.000356, ValAcc: 0.817500\n",
      "Stock: FB, Epoch: 800, TrainLoss: 0.000324, TrainAcc: 0.819861, Val.Loss: 0.000333, ValAcc: 0.816250\n",
      "Stock: FB, Epoch: 1000, TrainLoss: 0.000322, TrainAcc: 0.819722, Val.Loss: 0.000332, ValAcc: 0.817500\n",
      "------------------------\n",
      "Stock: NFLX, Epoch: 1, TrainLoss: 0.062595, TrainAcc: 0.051306, Val.Loss: 0.040228, ValAcc: 0.035714\n",
      "Stock: NFLX, Epoch: 200, TrainLoss: 0.000200, TrainAcc: 0.910429, Val.Loss: 0.000203, ValAcc: 0.910811\n",
      "Stock: NFLX, Epoch: 400, TrainLoss: 0.000184, TrainAcc: 0.919536, Val.Loss: 0.000187, ValAcc: 0.921530\n",
      "Stock: NFLX, Epoch: 600, TrainLoss: 0.000185, TrainAcc: 0.918665, Val.Loss: 0.000192, ValAcc: 0.911545\n",
      "Stock: NFLX, Epoch: 800, TrainLoss: 0.000180, TrainAcc: 0.917951, Val.Loss: 0.000182, ValAcc: 0.913688\n",
      "Stock: NFLX, Epoch: 1000, TrainLoss: 0.000179, TrainAcc: 0.923575, Val.Loss: 0.000181, ValAcc: 0.923652\n",
      "------------------------\n",
      "Stock: GOOGL, Epoch: 1, TrainLoss: 0.031859, TrainAcc: 0.099622, Val.Loss: 0.031239, ValAcc: 0.036221\n",
      "Stock: GOOGL, Epoch: 200, TrainLoss: 0.000195, TrainAcc: 0.910903, Val.Loss: 0.000200, ValAcc: 0.909412\n",
      "Stock: GOOGL, Epoch: 400, TrainLoss: 0.000189, TrainAcc: 0.915655, Val.Loss: 0.000193, ValAcc: 0.912270\n",
      "Stock: GOOGL, Epoch: 600, TrainLoss: 0.000185, TrainAcc: 0.915496, Val.Loss: 0.000187, ValAcc: 0.917270\n",
      "Stock: GOOGL, Epoch: 800, TrainLoss: 0.000178, TrainAcc: 0.915972, Val.Loss: 0.000180, ValAcc: 0.917979\n",
      "Stock: GOOGL, Epoch: 1000, TrainLoss: 0.000182, TrainAcc: 0.920567, Val.Loss: 0.000184, ValAcc: 0.922259\n",
      "------------------------\n",
      "Stock: AAPL, TestLoss: 0.000590, TestAcc: 0.713467\n",
      "Stock: AMZN, TestLoss: 0.061745, TestAcc: 0.085960\n",
      "Stock: FB, TestLoss: 0.000531, TestAcc: 0.676768\n",
      "Stock: NFLX, TestLoss: 0.001484, TestAcc: 0.495702\n",
      "Stock: GOOGL, TestLoss: 0.002280, TestAcc: 0.300860\n"
     ]
    }
   ],
   "source": [
    "processed_data = preprocess_data(all_data)\n",
    "n_hidden       = 20\n",
    "n_output_nodes = 1\n",
    "learning_rate  = 0.01\n",
    "epochs         = 1000\n",
    "\n",
    "my_models      = train_models(5, n_hidden, n_output_nodes, learning_rate, epochs, processed_data)\n",
    "evaluate_models(my_models, processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Yt38TeOVCIi",
    "outputId": "68cdacc3-1fcd-4bb6-e3b2-def0073f49ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock: AAPL, Epoch: 1, TrainLoss: 0.269170, TrainAcc: 0.031116, Val.Loss: 0.122506, ValAcc: 0.000000\n",
      "Stock: AAPL, Epoch: 200, TrainLoss: 0.000293, TrainAcc: 0.822441, Val.Loss: 0.000299, ValAcc: 0.822254\n",
      "Stock: AAPL, Epoch: 400, TrainLoss: 0.000285, TrainAcc: 0.823311, Val.Loss: 0.000295, ValAcc: 0.827229\n",
      "Stock: AAPL, Epoch: 600, TrainLoss: 0.000281, TrainAcc: 0.825291, Val.Loss: 0.000291, ValAcc: 0.828668\n",
      "Stock: AAPL, Epoch: 800, TrainLoss: 0.000276, TrainAcc: 0.829093, Val.Loss: 0.000285, ValAcc: 0.830805\n",
      "Stock: AAPL, Epoch: 1000, TrainLoss: 0.000271, TrainAcc: 0.832736, Val.Loss: 0.000280, ValAcc: 0.833647\n",
      "------------------------\n",
      "Stock: AMZN, Epoch: 1, TrainLoss: 0.010662, TrainAcc: 0.142074, Val.Loss: 0.015338, ValAcc: 0.082143\n",
      "Stock: AMZN, Epoch: 200, TrainLoss: 0.000101, TrainAcc: 0.963331, Val.Loss: 0.000108, ValAcc: 0.959296\n",
      "Stock: AMZN, Epoch: 400, TrainLoss: 0.000096, TrainAcc: 0.966500, Val.Loss: 0.000100, ValAcc: 0.965010\n",
      "Stock: AMZN, Epoch: 600, TrainLoss: 0.000091, TrainAcc: 0.967687, Val.Loss: 0.000098, ValAcc: 0.963587\n",
      "Stock: AMZN, Epoch: 800, TrainLoss: 0.000088, TrainAcc: 0.968954, Val.Loss: 0.000090, ValAcc: 0.969296\n",
      "Stock: AMZN, Epoch: 1000, TrainLoss: 0.000083, TrainAcc: 0.971489, Val.Loss: 0.000085, ValAcc: 0.970729\n",
      "------------------------\n",
      "Stock: FB, Epoch: 1, TrainLoss: 0.187148, TrainAcc: 0.036528, Val.Loss: 0.096354, ValAcc: 0.000000\n",
      "Stock: FB, Epoch: 200, TrainLoss: 0.000353, TrainAcc: 0.809722, Val.Loss: 0.000354, ValAcc: 0.813750\n",
      "Stock: FB, Epoch: 400, TrainLoss: 0.000341, TrainAcc: 0.814861, Val.Loss: 0.000348, ValAcc: 0.818750\n",
      "Stock: FB, Epoch: 600, TrainLoss: 0.000333, TrainAcc: 0.818472, Val.Loss: 0.000340, ValAcc: 0.815000\n",
      "Stock: FB, Epoch: 800, TrainLoss: 0.000303, TrainAcc: 0.840417, Val.Loss: 0.000310, ValAcc: 0.837500\n",
      "Stock: FB, Epoch: 1000, TrainLoss: 0.000291, TrainAcc: 0.841250, Val.Loss: 0.000298, ValAcc: 0.832500\n",
      "------------------------\n",
      "Stock: NFLX, Epoch: 1, TrainLoss: 0.030048, TrainAcc: 0.064384, Val.Loss: 0.023882, ValAcc: 0.070344\n",
      "Stock: NFLX, Epoch: 200, TrainLoss: 0.000194, TrainAcc: 0.914547, Val.Loss: 0.000199, ValAcc: 0.910826\n",
      "Stock: NFLX, Epoch: 400, TrainLoss: 0.000185, TrainAcc: 0.919061, Val.Loss: 0.000191, ValAcc: 0.917254\n",
      "Stock: NFLX, Epoch: 600, TrainLoss: 0.000182, TrainAcc: 0.921358, Val.Loss: 0.000190, ValAcc: 0.915111\n",
      "Stock: NFLX, Epoch: 800, TrainLoss: 0.000177, TrainAcc: 0.920408, Val.Loss: 0.000186, ValAcc: 0.919397\n",
      "Stock: NFLX, Epoch: 1000, TrainLoss: 0.000174, TrainAcc: 0.923892, Val.Loss: 0.000183, ValAcc: 0.920111\n",
      "------------------------\n",
      "Stock: GOOGL, Epoch: 1, TrainLoss: 0.009550, TrainAcc: 0.190357, Val.Loss: 0.014649, ValAcc: 0.129286\n",
      "Stock: GOOGL, Epoch: 200, TrainLoss: 0.000202, TrainAcc: 0.904646, Val.Loss: 0.000208, ValAcc: 0.900871\n",
      "Stock: GOOGL, Epoch: 400, TrainLoss: 0.000194, TrainAcc: 0.911299, Val.Loss: 0.000200, ValAcc: 0.909422\n",
      "Stock: GOOGL, Epoch: 600, TrainLoss: 0.000191, TrainAcc: 0.914626, Val.Loss: 0.000196, ValAcc: 0.912280\n",
      "Stock: GOOGL, Epoch: 800, TrainLoss: 0.000189, TrainAcc: 0.916368, Val.Loss: 0.000193, ValAcc: 0.914412\n",
      "Stock: GOOGL, Epoch: 1000, TrainLoss: 0.000185, TrainAcc: 0.917159, Val.Loss: 0.000189, ValAcc: 0.913703\n",
      "------------------------\n",
      "Stock: AAPL, TestLoss: 0.000607, TestAcc: 0.719198\n",
      "Stock: AMZN, TestLoss: 0.045638, TestAcc: 0.128940\n",
      "Stock: FB, TestLoss: 0.040280, TestAcc: 0.025253\n",
      "Stock: NFLX, TestLoss: 0.001869, TestAcc: 0.449857\n",
      "Stock: GOOGL, TestLoss: 0.007249, TestAcc: 0.160458\n"
     ]
    }
   ],
   "source": [
    "processed_data = preprocess_data(all_data)\n",
    "n_hidden       = 5\n",
    "n_output_nodes = 1\n",
    "learning_rate  = 0.01\n",
    "epochs         = 1000\n",
    "\n",
    "my_models      = train_models(5, n_hidden, n_output_nodes, learning_rate, epochs, processed_data)\n",
    "evaluate_models(my_models, processed_data)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ML Assignment 2 LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
